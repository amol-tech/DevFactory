{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DevFactory\\JupyterNoteBook_Dev\\workspace_BuildSystem\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree as ET\n",
    "import os.path\n",
    "from os import path\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE,STDOUT\n",
    "\n",
    "dir_workspace = os.path.join(os.getcwd(),'workspace_BuildSystem')\n",
    "print(dir_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function's  ####\n",
    "* get_package_tar_name_and_version - to get the package tar name and version by parsing package description\n",
    "* make_tarfile - to make tar file of given directory\n",
    "* set_package_name - set the package name in package description xml\n",
    "* get_fields - get all field name list for given field set id and for the given package element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_package_tar_name_and_version(file_package_desc):\n",
    "    tree = ET.parse(file_package_desc)\n",
    "    str_package_file_name = [elm_file.attrib['path'] for elm_file in tree.findall('.//Content/File') \n",
    "                             if elm_file.attrib['type'] == 'Package'][0]\n",
    "    str_package_version = [elm_package.attrib['version'] for elm_package in tree.findall('.//Package')][0] \n",
    "    return str_package_file_name,str_package_version\n",
    "\n",
    "def make_tarfile(output_filename, dir_source,exclude_parent=False):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        if(exclude_parent):\n",
    "            for f in os.listdir(dir_source):\n",
    "                file_path = os.path.join(dir_source,f)\n",
    "                tar.add(file_path,arcname=os.path.basename(file_path))\n",
    "        else:\n",
    "            tar.add(dir_source,arcname=os.path.basename(dir_source))\n",
    "            \n",
    "def set_package_name(file_package_desc,package_name):\n",
    "    tree = ET.parse(file_package_desc)\n",
    "    tree.find('Package').attrib['name'] = package_name\n",
    "    root = tree.getroot()    \n",
    "    tree.write(file_package_desc)\n",
    "\n",
    "def get_fields(tree,field_set_id):\n",
    "    fields = []\n",
    "    list_field_set  = [field_set for field_set in tree.findall('.//field_set') if field_set.attrib['id'] == field_set_id]\n",
    "    elm_field_set = list_field_set[0] if len(list_field_set) > 0 else None\n",
    "    if (elm_field_set != None) :\n",
    "        fields = [elm_field.attrib['name']+\"=>\"+elm_field.attrib['type'] for elm_field in elm_field_set.findall('field')]\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function : split_config ####\n",
    "* Read configuration xml file and split into multiple text files of fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_config(file_config,dir_out,dir_mapping):\n",
    "    dict_config = {}\n",
    "    with open(file_config, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "    dict_fields = {}\n",
    "    tree = ET.fromstring(content)\n",
    "    for elm_pkg in tree.findall('.//package'):\n",
    "        list_config_part = []\n",
    "        for elm_file in elm_pkg.findall('file'):\n",
    "            dict_config_part = {}\n",
    "            mfl = elm_pkg.attrib['mfl'] == 'true' if 'mfl' in elm_pkg.attrib else False\n",
    "            dict_config_part['mdx'] = os.path.join(dir_mapping, elm_file.attrib['base_mdx'] if mfl else elm_file.attrib['name'])\n",
    "            dict_config_part['version'] = elm_pkg.attrib['version']\n",
    "            \n",
    "            file_name = elm_pkg.attrib['name']+ '_' + elm_file.attrib['name'].replace('.mdx','').replace('*','all')+'_fields.txt'\n",
    "            list_fields = get_fields(elm_pkg,elm_file.attrib['field_set'])\n",
    "            if(len(list_fields) > 0) :\n",
    "                str_fields = '\\n'.join(list_fields)\n",
    "                dict_fields[file_name] = str_fields\n",
    "                dict_config_part['config'] = os.path.join(dir_out, file_name)\n",
    "            else:\n",
    "                dict_config_part['config'] = None\n",
    "            list_config_part.append(dict_config_part)\n",
    "        dict_config[elm_pkg.attrib['name']]=list_config_part \n",
    "        \n",
    "    for file_name in dict_fields:\n",
    "        path = os.path.join(dir_out, file_name)\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(dict_fields[file_name])\n",
    "        print('Processed file '+file_name)\n",
    "    return dict_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function : extract_package ####\n",
    "* Extract given package into directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_package(file_package, ):\n",
    "    if os.path.exists(dir_extract) and os.path.isdir(dir_extract):\n",
    "        shutil.rmtree(dir_extract)\n",
    "    os.mkdir(dir_extract) \n",
    "\n",
    "    file_package_target = os.path.join(dir_extract,os.path.basename(file_package))\n",
    "    shutil.copy(file_package,dir_extract)\n",
    "    with zipfile.ZipFile(file_package_target, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dir_extract)\n",
    "        \n",
    "    # Removing unwanted files \n",
    "    os.remove(file_package_target)\n",
    "    os.remove(os.path.join(dir_extract,'UsedFieldsReports.tar.gz'))\n",
    "    os.remove(os.path.join(dir_extract,'MappingReports.tar.gz'))\n",
    "    \n",
    "    # Creating required directory\n",
    "    os.mkdir(os.path.join(dir_extract,'UsedFieldsReports'))\n",
    "    os.mkdir(os.path.join(dir_extract,'MappingReports'))\n",
    "    \n",
    "    os.mkdir(os.path.join(dir_extract,'content'))\n",
    "    file_package_desc = os.path.join(dir_extract,'PackageDescription.xml')\n",
    "    package_tar_name,package_version = get_package_tar_name_and_version(file_package_desc)\n",
    "    file_tar = os.path.join(dir_extract,package_tar_name)\n",
    "    tar = tarfile.open(file_tar)\n",
    "    tar.extractall(os.path.join(dir_extract,'content')) \n",
    "    tar.close()\n",
    "    print('Package extracted successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function : build_package ####\n",
    "* To build the package with the content of given directory and package name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_package(dir_source,dir_out,package_name):\n",
    "    # Tar Used Field Report\n",
    "    dir_used_field_report = os.path.join(dir_source,'UsedFieldsReports')\n",
    "    make_tarfile(os.path.join(dir_source,'UsedFieldsReports.tar.gz'),dir_used_field_report)\n",
    "    shutil.rmtree(dir_used_field_report)\n",
    "    \n",
    "    # Tar Mapping Report\n",
    "    dir_mapping_report = os.path.join(dir_source,'MappingReports')\n",
    "    make_tarfile(os.path.join(dir_source,'MappingReports.tar.gz'),dir_mapping_report)\n",
    "    shutil.rmtree(dir_mapping_report)\n",
    "    \n",
    "    # Fetching attributes from Package Description\n",
    "    file_package_desc = os.path.join(dir_source,'PackageDescription.xml')\n",
    "    package_tar_name,package_version = get_package_tar_name_and_version(file_package_desc)\n",
    "    package_zip_name = 'Full_'+package_version.replace('.','_')+'_'+package_name.replace(' ','_')\n",
    "    file_package = os.path.join(dir_out,package_zip_name)\n",
    "    \n",
    "    # Set the package name\n",
    "    set_package_name(file_package_desc,package_name)\n",
    "    \n",
    "    # Tar Mapping Content  \n",
    "    dir_content = os.path.join(dir_source,'content')\n",
    "    make_tarfile(os.path.join(dir_source,package_tar_name),dir_content,exclude_parent=True)\n",
    "    shutil.rmtree(dir_content)\n",
    "    \n",
    "    shutil.make_archive(file_package,'zip',dir_source)\n",
    "    print('Package built successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dependencies(dir_dependencies,dir_temp):\n",
    "    dir_dep_inner = os.path.join(dir_dependencies,'inner')\n",
    "    for f in os.listdir(dir_dependencies):\n",
    "        if(os.path.isfile(os.path.join(dir_dependencies,f))):\n",
    "            shutil.copy(os.path.join(dir_dependencies,f),os.path.join(dir_temp,'content'))\n",
    "    for f in os.listdir(dir_dep_inner):\n",
    "        shutil.copy(os.path.join(dir_dep_inner,f),os.path.join(dir_temp,'content'+os.path.sep+'MappingSpecification'))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dependencies(dir_temp):\n",
    "    dir_outer = os.path.join(dir_temp,'content')\n",
    "    dir_inner = os.path.join(dir_temp,'content'+os.path.sep+'MappingSpecification')\n",
    "    files = [os.path.join(dir_outer,f) for f in os.listdir(dir_outer) if '.ttl' in f]\n",
    "    files = files + [os.path.join(dir_inner,f) for f in os.listdir(dir_inner) if '.ttl' in f]\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(file_build_config,file_package):\n",
    "    dir_temp = os.path.join(os.getcwd(),'temp')\n",
    "    dir_mapping = os.path.join(dir_temp,'content'+os.path.sep+'MappingSpecification')\n",
    "    dir_out = 'output'\n",
    "    dir_config = 'config'\n",
    "    dir_dependencies ='dependencies'\n",
    "\n",
    "    # Creating output directory\n",
    "    if os.path.exists(dir_out) and os.path.isdir(dir_out):\n",
    "        shutil.rmtree(dir_out)\n",
    "    os.mkdir(dir_out)\n",
    "\n",
    "    # Creating config directory\n",
    "    if os.path.exists(dir_config) and os.path.isdir(dir_config):\n",
    "        shutil.rmtree(dir_config)\n",
    "    os.mkdir(dir_config)\n",
    "\n",
    "    packages = split_config(file_build_config,dir_config,dir_mapping)\n",
    "    \n",
    "    file_cmd = 'generateSlimMappingForFields.cmd'\n",
    "    for package in packages:\n",
    "        extract_package(file_package,dir_temp)\n",
    "        # Copy Dependencies\n",
    "         (dir_dependencies,dir_temp)\n",
    "\n",
    "        for mdx_config in packages[package]:\n",
    "            if( mdx_config['config'] != None):\n",
    "                if('*.mdx' in mdx_config['mdx']):\n",
    "                    for f in os.listdir(dir_mapping):\n",
    "                        process = subprocess.run([file_cmd,os.path.join(dir_mapping,f), mdx_config['config']], \n",
    "                                                 check=True, stdout=subprocess.PIPE,universal_newlines=True, shell=True)\n",
    "                        print(process)\n",
    "                else:\n",
    "                    process = subprocess.run([file_cmd,mdx_config['mdx'], mdx_config['config']], \n",
    "                                                 check=True, stdout=subprocess.PIPE,universal_newlines=True, shell=True)\n",
    "                    print(process)\n",
    "            print('--------------------------------')   \n",
    "        # Remove Dependencies\n",
    "        remove_dependencies\n",
    "\n",
    "        build_package(dir_temp,dir_out,package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unit Testing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file Bloomberg_DL_End_of_Day_Pricing_R01_BBGlobalEquity_fields.txt\n",
      "Processed file Bloomberg_DL_End_of_Day_Pricing_R02_BBGlobalEquity_fields.txt\n",
      "Package extracted successfully\n",
      "D:\\DevFactory\\JupyterNoteBook_Dev\\temp\\content\\MappingSpecification\\BBGlobalEquity.mdx\n",
      "--------------------------------\n",
      "Package built successfully\n",
      "Package extracted successfully\n",
      "D:\\DevFactory\\JupyterNoteBook_Dev\\temp\\content\\MappingSpecification\\BBGlobalEquity.mdx\n",
      "--------------------------------\n",
      "Package built successfully\n"
     ]
    }
   ],
   "source": [
    "#Argument\n",
    "file_build_config = os.path.join(dir_workspace,'build_configuration.xml')\n",
    "file_package = os.path.join(dir_workspace,'Full_8_99_79_0_Bloomberg_DL_Global_Equity.zip')\n",
    "build(file_build_config,file_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package extracted successfully\n"
     ]
    }
   ],
   "source": [
    "dir_temp = os.path.join(dir_workspace,'temp')\n",
    "file_package = os.path.join(dir_workspace,'Full_8_99_79_0_Bloomberg_DL_Global_Equity.zip')\n",
    "extract_package(file_package,dir_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package built successfully\n"
     ]
    }
   ],
   "source": [
    "dir_temp = os.path.join(dir_workspace,'temp')\n",
    "dir_out =  os.path.join(dir_workspace,'out')\n",
    "build_package(dir_temp,dir_out,'Bloomberg DL Global Equity R01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file WM_GAT_R01_WM_GAT_Issue.mfl_fields.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WM_GAT_R01': [{'mdx': 'D:\\\\DevFactory\\\\JupyterNoteBook_Dev\\\\temp\\\\content\\\\MappingSpecification\\\\WM_Daten.mdx',\n",
       "   'version': 'R01',\n",
       "   'config': 'D:\\\\DevFactory\\\\JupyterNoteBook_Dev\\\\workspace_BuildSystem\\\\config\\\\WM_GAT_R01_WM_GAT_Issue.mfl_fields.txt'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_build_config = os.path.join(dir_workspace,'build_configuration.xml')\n",
    "dir_temp = os.path.join(os.getcwd(),'temp')\n",
    "dir_mapping = os.path.join(dir_temp,'content'+os.path.sep+'MappingSpecification')\n",
    "dir_config =  os.path.join(dir_workspace,'config')\n",
    "split_config(file_build_config,dir_config,dir_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
