{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0af5312-eff3-45e7-84a5-4ec78467558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workshops\\python_worksop\\env_nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>correctly</th>\n",
       "      <th>enter</th>\n",
       "      <th>home</th>\n",
       "      <th>is</th>\n",
       "      <th>marathi</th>\n",
       "      <th>name</th>\n",
       "      <th>nigam</th>\n",
       "      <th>please</th>\n",
       "      <th>sing</th>\n",
       "      <th>singer</th>\n",
       "      <th>so</th>\n",
       "      <th>song</th>\n",
       "      <th>sonu</th>\n",
       "      <th>versatile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address  also  and  correctly  enter  home  is  marathi  name  nigam  \\\n",
       "0        1     0    1          0      0     1   1        0     0      1   \n",
       "1        0     0    0          0      0     0   1        0     0      1   \n",
       "2        0     1    0          0      0     0   0        1     0      1   \n",
       "3        1     0    1          1      1     0   0        0     1      0   \n",
       "\n",
       "   please  sing  singer  so  song  sonu  versatile  \n",
       "0       0     0       0   2     0     1          0  \n",
       "1       0     0       1   0     0     1          1  \n",
       "2       0     1       0   0     1     1          0  \n",
       "3       1     0       0   0     0     0          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "count_vect = CountVectorizer()\n",
    "doc1 = 'Sonu NIgam  home address is so and so'\n",
    "doc2 = 'Sonu Nigam is versatile singer'\n",
    "doc3 = 'Sonu nigam also sing marathi song'\n",
    "doc4 = 'Please enter name and address correctly'\n",
    "\n",
    "corpus = [doc1,doc2,doc3,doc4]\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(corpus)\n",
    "\n",
    "df_bow = pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names())\n",
    "df_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660334db-c693-4a01-8c7f-9078f58b508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    tokens = [word for word in nltk.word_tokenize(text) if len(word) > 1] \n",
    "    stems = [stemmer.stem(item) for item in tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf956b44-e1ba-4df1-9cbb-5ba5115a0da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workshops\\python_worksop\\env_nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "d:\\workshops\\python_worksop\\env_nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>also</th>\n",
       "      <th>correctli</th>\n",
       "      <th>enter</th>\n",
       "      <th>home</th>\n",
       "      <th>marathi</th>\n",
       "      <th>name</th>\n",
       "      <th>nigam</th>\n",
       "      <th>pleas</th>\n",
       "      <th>sing</th>\n",
       "      <th>singer</th>\n",
       "      <th>song</th>\n",
       "      <th>sonu</th>\n",
       "      <th>versatil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380444</td>\n",
       "      <td>0.596039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    address      also  correctli     enter      home   marathi      name  \\\n",
       "0  0.505100  0.000000   0.000000  0.000000  0.640655  0.000000  0.000000   \n",
       "1  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.455732   0.000000  0.000000  0.000000  0.455732  0.000000   \n",
       "3  0.366739  0.000000   0.465162  0.465162  0.000000  0.000000  0.465162   \n",
       "\n",
       "      nigam     pleas      sing    singer      song      sonu  versatil  \n",
       "0  0.408922  0.000000  0.000000  0.000000  0.000000  0.408922  0.000000  \n",
       "1  0.380444  0.000000  0.000000  0.596039  0.000000  0.380444  0.596039  \n",
       "2  0.290888  0.000000  0.455732  0.000000  0.455732  0.290888  0.000000  \n",
       "3  0.000000  0.465162  0.000000  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import webtext,stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "vectorizer_X = TfidfVectorizer(ngram_range=(1,1),stop_words=stop_words,tokenizer=tokenize)\n",
    "transform_X = vectorizer_X.fit_transform(corpus)\n",
    "\n",
    "doc_y = 'Tik tik si the marathi song sung by sonu nigam'\n",
    "transform_y = vectorizer_X.transform([doc_y])\n",
    "\n",
    "\n",
    "df_tfidf = pd.DataFrame(transform_X.toarray(),columns=vectorizer_X.get_feature_names())\n",
    "df_tfidf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe283c32-46c6-4201-ba46-006f7266336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311144</td>\n",
       "      <td>0.289475</td>\n",
       "      <td>0.764602</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3\n",
       "0  0.311144  0.289475  0.764602  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "result = cosine_similarity(transform_y,transform_X)\n",
    "pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
