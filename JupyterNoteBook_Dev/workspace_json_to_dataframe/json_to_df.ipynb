{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from json_flatten import flatten\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import jmespath\n",
    "\n",
    "dir_workspace = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to add list object in child data list by creating id reference\n",
    "def add_to_child_data_list(id_val,parent,child,list_data,list_child_data_dict):\n",
    "    dict_id = {}\n",
    "    dict_id['ID'] = id_val\n",
    "    dict_id['PARENT'] = parent\n",
    "    dict_id['CHILD'] = child\n",
    "    dict_id['DATA'] = list_data\n",
    "    list_child_data_dict.append(dict_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to remove list object from given dictionary recursively and add it into child data list\n",
    "def remove_list_and_inject_pk(dict_data,parent,id_val,list_child_data_dict):\n",
    "    for key in dict_data.keys():\n",
    "        if isinstance(dict_data[key],list):\n",
    "            # Removing list and injecting ID value at same place\n",
    "            list_x = dict_data[key]\n",
    "            dict_data[key] = id_val\n",
    "            add_to_child_data_list(id_val,parent,key,list_x,list_child_data_dict)\n",
    "            \n",
    "            # Recursion\n",
    "            for dict_child in list_x:\n",
    "                remove_list_and_inject_pk(dict_child,key,'#ID#'+str(uuid.uuid1()),list_child_data_dict)\n",
    "        \n",
    "        elif isinstance(dict_data[key],dict):\n",
    "            remove_list_and_inject_pk(dict_data[key],parent,id_val,list_child_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to process list of dictionary object and assign PK and FK\n",
    "def process_list(list_data,pk_col,fk_col=None,fk_col_id=None):\n",
    "    list_data_in = [flatten(d) for d in list_data]\n",
    "    list_data_out = []\n",
    "    for dict_in in list_data_in:\n",
    "        dict_out = {}\n",
    "        for key in dict_in:\n",
    "            if '#ID#' in dict_in[key]:\n",
    "                dict_out[pk_col] = dict_in[key]\n",
    "            else:\n",
    "                #dict_out[key] = dict_in[key]\n",
    "                dict_out[key[key.rfind('.')+1:]] = dict_in[key]\n",
    "        if(fk_col != None and fk_col_id != None):\n",
    "            dict_out[fk_col] = fk_col_id\n",
    "        list_data_out.append(dict_out)\n",
    "    return list_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to create internal ID column for join operation which will be dropped finally\n",
    "def get_col_name(elm_name):\n",
    "    return elm_name.upper()+'_ID_DROP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to return filtered json object by jmes path\n",
    "def get_filter_json(json,instruc_set):\n",
    "    expression = jmespath.compile(instruc_set)\n",
    "    return expression.search(json)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to merge multiple list which having element name\n",
    "def process_child_data_list(list_child_data_dict,dict_final_child_data):\n",
    "    for dict_x in list_child_data_dict:\n",
    "        child_key = dict_x['PARENT']+'.'+dict_x['CHILD']\n",
    "        if(child_key in dict_final_child_data):\n",
    "            list_existing = dict_final_child_data[child_key]['DATA']\n",
    "            list_out = process_list(dict_x['DATA'],get_col_name(dict_x['CHILD']),get_col_name(dict_x['PARENT']),dict_x['ID'])\n",
    "            list_existing.extend(list_out)\n",
    "        else:\n",
    "            dict_attr = {}\n",
    "            list_out = process_list(dict_x['DATA'],get_col_name(dict_x['CHILD']),get_col_name(dict_x['PARENT']),dict_x['ID'])\n",
    "            dict_attr['DATA'] = list_out\n",
    "            dict_attr['FK_COL'] = get_col_name(dict_x['PARENT'])\n",
    "            dict_final_child_data[child_key] = dict_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Unused methods\n",
    "def get_filter_set(dict_group,filter_list):\n",
    "    list_final = []\n",
    "    for df_name in filter_list:\n",
    "        list_inner = []\n",
    "        add_hierarchy(dict_group,list_inner,df_name)\n",
    "        list_final.extend(list_inner)\n",
    "    return set(list_final)\n",
    "\n",
    "def add_hierarchy(dict_group,list_parent,child):\n",
    "    if (child in dict_group):\n",
    "        list_parent.append(child)\n",
    "        if dict_group[child] != 'Root':\n",
    "            add_hierarchy(dict_group,list_parent,dict_group[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main method which will return datafrome for given json_data object\n",
    "def json_to_dataframe(json_data, instruction_set=None, merge=True, drop_id_col=True, debug=False, filter_path=None):\n",
    "    list_child_data_dict = []\n",
    "    dict_final_child_data = {}\n",
    "\n",
    "    if (instruction_set != None):\n",
    "        expression = jmespath.compile(instruction_set)\n",
    "        json_data = expression.search(json_data)\n",
    "        with open('debug.json', 'w') as fp:\n",
    "            json.dump(json_data, fp)\n",
    "        \n",
    "\n",
    "    # Step 0 : Prepare the root list from input json_data\n",
    "    if isinstance(json_data, dict):\n",
    "        if len(json_data) == 1 and isinstance(json_data.get(list(json_data.keys())[0]), list):\n",
    "            list_root = json_data.get(list(json_data.keys())[0])\n",
    "        else:\n",
    "            list_root = []\n",
    "            list_root.append(json_data)\n",
    "    elif isinstance(json_data, list):\n",
    "        list_root = json_data\n",
    "    else:\n",
    "        print('Exception')\n",
    "\n",
    "    # Step 1 : Remove list data element from dict and inject primary key id\n",
    "    for dict_root in list_root:\n",
    "        remove_list_and_inject_pk(dict_root, 'Root', '#ID#' + str(uuid.uuid1()), list_child_data_dict)\n",
    "\n",
    "    # Step 2 : process root list\n",
    "    data_root_out = process_list(list_root, get_col_name('Root'))\n",
    "\n",
    "    # Step 3 : process child list\n",
    "    process_child_data_list(list_child_data_dict, dict_final_child_data)\n",
    "\n",
    "    # Step 4 : Dataframe Creation\n",
    "    df_root = pd.DataFrame(data_root_out)\n",
    "    df_final = df_root\n",
    "\n",
    "    dict_all = {}\n",
    "    dict_all['root'] = df_root\n",
    "\n",
    "    # To remove duplicate list data if they have found under different parent\n",
    "    if(len(list_child_data_dict) > 0):\n",
    "        df_debug = pd.DataFrame(list_child_data_dict)\n",
    "        df_group = df_debug[['PARENT', 'CHILD']].drop_duplicates()\n",
    "        filter_path = 'Root.'+filter_path if filter_path != None else None\n",
    "        filter_list = [key for key in dict_final_child_data if filter_path == None or key in filter_path]\n",
    "        \n",
    "    # Merging of datagroup\n",
    "    for key in dict_final_child_data:\n",
    "        df_child = pd.DataFrame(dict_final_child_data[key]['DATA'])\n",
    "        dict_all[key] = df_child\n",
    "        if (merge and key in filter_list):\n",
    "            df_final = pd.merge(df_final, df_child, how='left', left_on=dict_final_child_data[key]['FK_COL'],\n",
    "                                right_on=dict_final_child_data[key]['FK_COL'])\n",
    "\n",
    "    # Add meta dataframe for debug purpose\n",
    "    if (debug):\n",
    "        df_debug = pd.DataFrame(list_child_data_dict)\n",
    "        dict_all['meta-debug'] = df_debug\n",
    "        dict_all['meta-group'] = df_group\n",
    "\n",
    "    if (drop_id_col):\n",
    "        cols_to_drop = [c for c in list(df_final.columns) if '_ID_DROP' in c]\n",
    "        df_final.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    return df_final, dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PreferredInstrumentName</th>\n",
       "      <th>rel</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JP3814000000</td>\n",
       "      <td>self</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>JP3814000000</td>\n",
       "      <td>next</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>JP3814000000</td>\n",
       "      <td>first</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JP3542400001</td>\n",
       "      <td>self</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>JP3542400001</td>\n",
       "      <td>next</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>JP3216200000</td>\n",
       "      <td>next</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>JP3216200000</td>\n",
       "      <td>first</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>JP3215800008</td>\n",
       "      <td>self</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>JP3215800008</td>\n",
       "      <td>next</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>JP3215800008</td>\n",
       "      <td>first</td>\n",
       "      <td>http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PreferredInstrumentName    rel  \\\n",
       "0              JP3814000000   self   \n",
       "1              JP3814000000   next   \n",
       "2              JP3814000000  first   \n",
       "3              JP3542400001   self   \n",
       "4              JP3542400001   next   \n",
       "..                      ...    ...   \n",
       "295            JP3216200000   next   \n",
       "296            JP3216200000  first   \n",
       "297            JP3215800008   self   \n",
       "298            JP3215800008   next   \n",
       "299            JP3215800008  first   \n",
       "\n",
       "                                                  link  \n",
       "0    http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "1    http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "2    http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "3    http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "4    http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "..                                                 ...  \n",
       "295  http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "296  http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "297  http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "298  http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "299  http://invm48.gsc.zz:8180/GSOService/gso?gsoNa...  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Price Example\n",
    "with open(os.path.join(dir_workspace,'data_part.json')) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "#instruc_set= 'Entities[].QuantLibCurveSurface.IssueCurveAndSurfaceCharacteristics..{Output : IssueCurveAndSurfaceCharacteristics}'\n",
    "\n",
    "df_out,dict_all = json_to_dataframe(json_data)\n",
    "df_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
